{
  "hash": "91b1072c08814cb74c58032a88968322",
  "result": {
    "markdown": "---\ntitle: \"Efectividad de repelentes de insectos\"\nsubtitle: \"Bayesian Poisson models\"\nauthor: \"Asael Alonzo Matamoros\"\ndate: \"2022-12-01\"\ncategories: [Bayesian,analysis,code, Poisson]\nimage: \"image.jpg\"\nbibliography: ref.bib\nformat: \n  html:\n    toc: true\n    code-copy: true\n    smooth-scroll: true\n    anchor-sections: true\n---\n\n\nEste post muestra los pasos del Bayesian Workflow para analizar la base de datos  `Insects-Spray`.\n\nSe desea evaluar la efectividad de seis diferentes tipos de repelentes para insectos ($A,B,\\ldots,F$). El experimento consiste en contar el número de insectos en cierta área delimitada, horas después de aplicar cierto tipo de repelente. El experimento se replicó 72 veces, 12 veces para cada uno de los tipos de repelente.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(flextable)\nlibrary(bayesplot)\nlibrary(posterior)\n\ndata(\"InsectSprays\")\n```\n:::\n\n\nLa @fig-box resume la distribución y valores medios del número de insectos encontrados en cada uno de los tipos de repelente utilizados. Claramente, las distribuciones son no simétricas y muy heterogéneas entre cada uno de los tipos, y los datos son de tipo discreto, por lo tanto se descartan los supuestos de normalidad. \n\nSupondremos tres modelos  distintos:\n\n + Modelo de Poisson, con parámetro $\\lambda$ desconocido y prior conjugada de tipo Gamma:\n \n$$M_1: \\ y_i \\sim Poisson(\\lambda), \\quad \\lambda \\sim Gamma(\\alpha,\\beta).$$\n \n  + Modelo Binomial negativa, con parámetro $p$ desconocido y prior dispersa:\n  \n$$M_2: \\ y_i \\sim \\text{Neg-Binom}(n,p), \\quad \\lambda \\sim U(1,1).$$\n \n + Modelo de Poisson, con parámetro $\\lambda$ desconocido y prior no conjugada de tipo Normal:\n \n$$M_3: \\ y_i \\sim Poisson(\\lambda), \\quad \\lambda \\sim N(\\mu,\\sigma^2).$$\n\nNote que en cada modelo, no consideramos la dispersión entre grupos presente en los datos, simplemente queremos modelar la distribución global del número de insectos contabilizados independiente del repelente utilizado. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aes(y = count, x = spray,fill = spray),data = InsectSprays)+\n  geom_boxplot()+\n  labs(title = \"Número de insectos por tipo de repelente\",\n       x = \"tipo de repelente\",y = \"Número de insectos\")\n```\n\n::: {.cell-output-display}\n![Gráfico de cajas. Cada caja representa una distribución por cuantiles del número de insectos encontrados en cada uno de los tipos de repelentes. Los repelentes de tipo A,B y F, presentan más insectos que las cajas C, D y E. Además, las dispersiones de los primeros tres tipos son mayores a las dispersiones presentadas en las cajas C, D y E.](index_files/figure-html/fig-box-1.png){#fig-box width=672}\n:::\n:::\n\n\nLos ejemplos propuestos se resolverán de tres diferentes formas:\n \n  1. Los modelos $M_1$ y $M_2$ se resolverán con un Gibbs sampler, que para estos casos es un simple MC.\n \n  2. El modelo $M_3$ se resolverá con un Metrópolis-Hastings.\n\n## Modelo $M1$ de Poisson Conjugado\n\nSe define el número de insectos encontrado como una variable aleatoria discreta de tipo Poisson con parámetro $\\lambda$ desconocido ($y_i \\sim Poisson(\\lambda)$) y aleatorio, la priori para $\\lambda$ es una prior conjugada y \"poco informativa\". Asumamos que los repelentes aplicados son efectivos y elegir una prior Gamma tal que centre la probabilidad en valores cercanos al cero. \n\n### Selección de la prior\n\nEn este caso, la prior a usar es:\n\n$$\\lambda \\sim Gamma(3,3).$$\n@fig-priors1 presenta posibles candidatos a priors para el parámetro $\\lambda$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nx = c(rgamma(600,2,4),rgamma(600,3,3),rgamma( 600,5,2))\ny = c(rep(\"G(2,4)\",600),rep(\"G(3,3)\",600),rep(\"G(5,2)\",600))\n\ndf = data.frame(sim = x, dist = y)\n\nggplot(aes(x = sim,fill = dist),data = df)+\n  geom_density(alpha = 0.4)+\n  labs(title = \"Diferentes tipos de priors\",\n       x = \"Simulaciones\",y = \"densidad\")\n```\n\n::: {.cell-output-display}\n![Gráfico de densidades. Se comparan tres distribuciones Gamma como posibles candidatos para priors de lambda, las tres priors tienen medias similares alrededor de 9, pero la prior G(2,4) es la que provee mayor dispersión, siendo más sujetiva.](index_files/figure-html/fig-priors1-1.png){#fig-priors1 width=672}\n:::\n:::\n\n\nLa distribución a posteriori para $\\lambda$ es:\n\n$$\\lambda |y \\sim Gamma(3 + \\sum_{i=1}^n y_i,3+n).$$\n\nDonde, $\\sum_{i=1}^n y_i =$ 684 y $n = 72$. Por lo tanto la posterior final es: $\\lambda |y \\sim Gamma (687,75)$.\n\n### Estimadores puntuales\n\nEl estimador puntual para $\\lambda$ es:\n\n$$\\hat \\lambda = E[\\lambda | y] = \\frac{687}{75} \\approx 9.16.$$\n@fig-reslt1 muestra la comparación de las densidades prior y posterior para el modelo Poisson, pese que la prior se eligió con el propósito de ser no informativa, la posterior es muy especifica y centrada en su primer momento.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx = c(rgamma(600,3,3),rgamma(600,687,75))\ny = c(rep(\"Prior\",600),rep(\"Posterior\",600))\n\ndf = data.frame(sim = x, dist = y)\n\nggplot(aes(x = sim,fill = dist),data = df)+\n  geom_density(alpha = 0.4)+\n  labs(title = \"Comparación Prior | Posterior\",\n       subtitle = \"Modelo Poisson Conjugado\",\n       x = \"Simulaciones\",y = \"densidades\")\n```\n\n::: {.cell-output-display}\n![Gráfico de densidades. Comparamos la distribuciones a Priori | Posteriori para el modelo Poisson  conjugado, pese que la prior esta focalizada cerca de cero, la posterior se corre a la media de los datos, con muy poca dispersión, siendo muy especifica.](index_files/figure-html/fig-reslt1-1.png){#fig-reslt1 width=672}\n:::\n:::\n\n\nLos intervalos de credibilidad se encuentran mediante `Monte-Carlo`. Los intervalos de credibilidad al 90% para la posterior son:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIC = quantile(rgamma(600,687,75),probs = c(0.05,0.95))\nIC\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      5%      95% \n8.619652 9.732203 \n```\n:::\n:::\n\n\n### Posterior predictive checks\n\nEn este caso se realizaran comparaciones de la densidad predictiva del modelo, esta se puede estimar con `Monte-Carlo` mediante el siguiente procedimiento.\n\n  1. Para $k = 1,2,\\ldots,w$; hacer\n    \n     - 1.1 Simular un valor $\\lambda_k$ de la posterior $Gamma(687,75)$.\n     \n     - 1.2  Simular un valor de la verosimilitud $y^*_k \\sim Poisson(\\lambda_k)$.\n    \n  2. Los  valores $y^*_1,y^*_2,\\ldots,y^*_w$ son una muestra de $y^* | y$.\n\n@fig-ppc1 compara las predictivas distribuciones obtenidas, notamos que la función predictiva esta muy centrada en el valor esperado de los datos, y provee un ajuste muy pobre.\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot_theme_set(theme_grey())\n# Predictive\nyrep = rep(rpois(600,rgamma(600,687,75)),72)\nyrep = matrix(yrep,ncol = 72,byrow = TRUE)\n\ny = InsectSprays$count\n\nppc_dens_overlay(y, yrep[1:200,])+\n  labs(title = \"Posterior Predictive Checks\",\n       subtitle = \"Modelo Poisson Conjugado\")\n```\n\n::: {.cell-output-display}\n![Gráfico de densidades. Comparamos la distribuciones a predictiva y muestra para el modelo Poisson  conjugado.](index_files/figure-html/fig-ppc1-1.png){#fig-ppc1 width=672}\n:::\n:::\n\n\n## Modelo $M_2$ de Binomial Negativa con priori dispersa\n\nSe define el número de insectos encontrado como una variable aleatoria discreta Binomial negativa con parámetro $p$ desconocido y $m = 30$ repeticiones, ($y_i \\sim \\text{Neg=Binom}(30,p)$). La prior es conjugada para $p$ es la distribución Beta. \n\n$$p \\sim Beta(\\alpha,\\beta).$$\n\nEsta prior genera una posterior de tipo Beta, pero si $\\alpha = \\beta = 1$ la distribución es uniforme en el intervalo unitario, que a su vez es una prior dispersa para $p$.\n\nLa posterior para $p$ es:\n\n$$p | y \\sim Beta(1 + 30n,1+\\sum_{i=1}^n y_i).$$\n\nPor lo tanto, la posterior final es: $p |y \\sim Beta (2160,685)$. Los estimadores puntuales y por intervalos son:\n\n$$\\hat p = E[p | y] = \\frac{2160}{2160+685} \\approx 0.759,$$\ny los intervalos de credibilidad al 90% :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIC = quantile(rbeta(600,2160,685),probs = c(0.05,0.95))\nIC\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       5%       95% \n0.7468257 0.7732343 \n```\n:::\n:::\n\n\nLos dos valores anteriores no brindan información del fenómeno de estudio, para una mejor interpretador, calculamos el número de insectos esperado a posterior, esto es, el valor esperado de la función de probabilidad que modela los datos, calculado con el estimador puntual obtenido\n\n$$E[y|p = \\hat p] = \\frac{r(1-\\hat p)}{\\hat p} \\approx 10.$$\nEl número esperado de insectos con el modelo Binomial negativa es de 10 insectos, que es mayor al obtenido por el modelo $M_1$ cuyo valor esperado fue de 9.16 insectos.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Código preliminar al gráfico\nbayesplot_theme_set(theme_grey())\n\n# Compare distributions\nx = c(rbeta(600,1,1),rbeta(600,2160,685))\ny = c(rep(\"Prior\",600),rep(\"Posterior\",600))\n\ndf = data.frame(sim = x, dist = y)\n\n# posterior predictive checks\nyrep = rep(rnbinom(600,size = 30,rbeta(600,2160,685)),72)\nyrep = matrix(yrep,ncol = 72,byrow = TRUE)\n\ny = InsectSprays$count\n```\n:::\n\n::: {#fig-reslt2 .cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nggplot(aes(x = sim,fill = dist),data = df)+\n  geom_density(alpha = 0.4)+\n  labs(title = \"Comparación Prior | Posterior\",\n       subtitle = \"Modelo Binomial-Negativa dispersa\",\n       x = \"Simulaciones\",y = \"densidades\")\n\nppc_dens_overlay(y, yrep[1:200,])+\n  labs(title = \"Posterior Predictive Checks\",\n       subtitle = \"Modelo Binomial Negativa dispersa\")\n```\n\n::: {.cell-output-display}\n![Comparamos la densidades a Priori | Posteriori y obtenemos una posterior muy especifica pese lo dispersa que es la prior.\"](index_files/figure-html/fig-reslt2-1.png){#fig-reslt2-1 width=672}\n:::\n\n::: {.cell-output-display}\n![La densidad predictiva del modelo muestra el mal ajuste a los datos, el modelo no captura la dispersion y asimetría de la muestra.\"](index_files/figure-html/fig-reslt2-2.png){#fig-reslt2-2 width=672}\n:::\n\nComparación de la posterior vs prior y análisis del ajuste del modelo mediante la densidad predictiva, modelo Binomial negativa.\n:::\n\n\n@fig-reslt2 muestra la comparación de las densidades prior y posterior para el modelo Binomial negativa, pese la sobre-dispersión de la prior, se obtiene una posterior muy informativa y especifica. El gráfico derecho compara las predictivas obtenidas, notamos que la función predictiva esta muy centrada en el valor esperado de los datos, y provee un ajuste muy pobre.\n\n## Modelo $M_3$ de Poisson con prior débil\n\nSe define el número de insectos encontrado como una variable aleatoria discreta de tipo Poisson con parámetro $\\lambda$ desconocido ($y_i \\sim Poisson(\\lambda)$) y aleatorio, la prior para $\\lambda$ es\n\n$$\\lambda \\sim N(8,1).$$\nEn este caso la prior es no conjugada y se debe realizar el `algoritmo de Metrópolis`, @metropolis1953. El siguiente código muestra la implementación del algoritmo para nuestro modelo, la primera función calcula la densidad propuesta que es simplemente el producto de le verosimilitud y la prior, ($f_p(\\theta) = f(y|\\theta)f(\\theta)$). La segunda función es del algoritmo mismo.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npost = function(y,lambda,mu,sigma){\n  prior = dnorm(lambda,mean = mu,sd = sigma)\n  like = prod(dpois(x = y,lambda = lambda))\n  post = like*prior\n  \n  return(post)\n}\n\nmetropolis = function(y, mu, sigma = 1,iter = 5000,inits = rnorm(1, 5,1)){\n  lbd = rep(0,iter) \n  lbd[1] = inits\n  for (i in 2:iter) {\n    temp = rnorm(1,mean = lbd[i-1])\n    \n    p1 = post(y,lambda = temp,mu = mu,sigma = sigma)\n    p2 = post(y,lambda = lbd[i-1],mu = mu,sigma = sigma)\n    pa = p1/p2\n    \n    lbd[i] = lbd[i-1]\n    \n    if(pa > runif(1))\n      lbd[i] = temp\n      \n  }\n  return(lbd)\n}\n```\n:::\n\n\nPara este ejemplo simulamos dos cadenas independientes de 5,000 iteraciones, donde el valor inicial de cada cadena se simuló de una normal con media cinco y varianza uno.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda1 = metropolis(y = InsectSprays$count,mu = 8)\nlambda2 = metropolis(y = InsectSprays$count,mu = 8)\n\ndf1 = data.frame(chain = sort(rep(1:2,4000)),\n                lambda = c(lambda1[1001:5000],lambda2[1001:5000]))\npdf = posterior::as_draws(df1)\n\nmcmc_combo(x = df1,pars = \"lambda\")\n```\n\n::: {.cell-output-display}\n![Gráfico de las posterior. Presentamos los traceplot y densidades de la posterior simulada, usando 2 cadenas de 5000 iteraciones y Warm-up: 1000 iteraciones.](index_files/figure-html/fig-chain-1.png){#fig-chain width=672}\n:::\n:::\n\n\n@fig-chain muestra los trace-plots de ambas cadenas que se entrelazan entre ellas indicando estacionariadad y convergenica, el grafico de densidades es uni modal y simétrico indicando convergencia. @tbl-post2 muestra las estadísticas resumen de la posterior de $\\lambda$, dos indicadores importantes muestran convergencia de las cadenas, el *effective sample size* (ess) que indica el número de muestras independientes a las que equivalen las muestras obtenidas de la cadenas, dichos valores deben ser similar al número de iteraciones. El factor de convergencia $\\hat R$ es un valor que compara las varianzas de las cadenas, valores aproximados a 1 indican convergencia.\n\n\n::: {#tbl-post2 .cell tbl-cap='Criterios de información de los modelos. Mediante Validación cruzada. La tabla presenta los criterios AIC, RMSE, MAE y MAPE bajo un 10-fold cv.'}\n\n```{.r .cell-code}\nx = summarise_draws(pdf)\nft = flextable(x[2,])\nautofit(ft)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-4cae1b08{}.cl-4ca8ec46{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4cab17d2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4cab17dc{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4cab26d2{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cab26d3{width:0.922in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cab26dc{width:1.007in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cab26dd{width:0.965in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cab26e6{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cab26e7{width:0.922in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cab26f0{width:1.007in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cab26f1{width:0.965in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-4cae1b08'><caption></caption><thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-4cab26d2\"><p class=\"cl-4cab17d2\"><span class=\"cl-4ca8ec46\">variable</span></p></td><td class=\"cl-4cab26d3\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">mean</span></p></td><td class=\"cl-4cab26d3\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">median</span></p></td><td class=\"cl-4cab26dc\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">sd</span></p></td><td class=\"cl-4cab26dc\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">mad</span></p></td><td class=\"cl-4cab26d3\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">q5</span></p></td><td class=\"cl-4cab26d3\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">q95</span></p></td><td class=\"cl-4cab26d3\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">rhat</span></p></td><td class=\"cl-4cab26dd\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">ess_bulk</span></p></td><td class=\"cl-4cab26dd\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">ess_tail</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-4cab26e6\"><p class=\"cl-4cab17d2\"><span class=\"cl-4ca8ec46\">lambda</span></p></td><td class=\"cl-4cab26e7\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">9.322206</span></p></td><td class=\"cl-4cab26e7\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">9.321581</span></p></td><td class=\"cl-4cab26f0\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">0.3339866</span></p></td><td class=\"cl-4cab26f0\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">0.3154818</span></p></td><td class=\"cl-4cab26e7\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">8.761132</span></p></td><td class=\"cl-4cab26e7\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">9.879135</span></p></td><td class=\"cl-4cab26e7\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">1.000253</span></p></td><td class=\"cl-4cab26f1\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">1,664.757</span></p></td><td class=\"cl-4cab26f1\"><p class=\"cl-4cab17dc\"><span class=\"cl-4ca8ec46\">1,451.404</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n@tbl-post2 muestra la media a posterior e intervalos de credibilidad para la posterior de $\\lambda$. Además, se muestra el error de `Monte-Carlo`, dicho error debe ser cercano a 0, valores muy grandes indican alta dispersión de las simulaciones que se interpreta como una mala aproximación del método.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Preliminar\nbayesplot_theme_set(theme_grey())\n\nx = c(rnorm(600,8,1),pdf$lambda[1001:1600])\ny = c(rep(\"Prior\",600),rep(\"Posterior\",600))\n\ndf = data.frame(sim = x, dist = y)\n\n# Predictive\nyrep = rep(rpois(600,pdf$lambda[1001:1600]),72)\nyrep = matrix(yrep,ncol = 72,byrow = TRUE)\n\ny = InsectSprays$count\n```\n:::\n\n::: {#fig-reslt3 .cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nggplot(aes(x = sim,fill = dist),data = df)+\n  geom_density(alpha = 0.4)+\n  labs(title = \"Comparación Prior | Posterior\",\n       subtitle = \"Modelo Poisson con prior normal\",\n       x = \"Simulaciones\",y = \"densidades\")\n\nppc_dens_overlay(y, yrep[1:200,])+\n  labs(title = \"Posterior Predictive Checks\",\n       subtitle = \"Modelo Poisson con Prior débil\")\n```\n\n::: {.cell-output-display}\n![Comparamos la densidades a Priori | Posteriori y obtenemos una posterior muy especifica pese lo dispersa que es la prior.\"](index_files/figure-html/fig-reslt3-1.png){#fig-reslt3-1 width=672}\n:::\n\n::: {.cell-output-display}\n![La densidad predictiva del modelo muestra el mal ajuste a los datos, el modelo no captura la dispersion y asimetría de la muestra.\"](index_files/figure-html/fig-reslt3-2.png){#fig-reslt3-2 width=672}\n:::\n\nComparación de la posterior vs prior y análisis del ajuste del modelo mediante la densidad predictiva, modelo de Poisson con prior no conjugada.\n:::\n\n\n@fig-reslt3 muestra la comparación de las densidades prior y posterior para el modelo Poisson, la dinámica entre la prior y posterior es mas natural, pero la influencia de los datos hace que la prior sea de leve influencia en la posterior. El gráfico derecho compara las predictivas obtenidas, notamos que la función predictiva está muy centrada en el valor esperado de los datos, y provee un ajuste muy pobre.\n\n### Selección de Modelos\n\nPara seleccionar el mejor modelo de los tres, utilizaremos los cuatro criterios definidos, Factor de Bayes, log-likelihood elpd, y WAIC.\n\n#### Factores de Bayes\n\nEl código para calcular la densidad marginal de cada modelo es:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nMarginal1 = function(y,iter = 10000){\n  mar = 1:iter\n  \n  for (i in 1:iter) {\n    mar[i] = sum(dpois(x = y,lambda = rgamma(n = 1,shape = 3,3),log = TRUE))\n  }\n  return(mean( exp(mar) ))\n}\nMarginal2 = function(y,iter = 10000){\n  mar = 1:iter\n  \n  for (i in 1:iter) {\n    mar[i] = sum(dnbinom(x = y,prob = rbeta(1,1,1),size = 30,log = TRUE))\n  }\n  return(mean( exp(mar) ))\n}\nMarginal3 = function(y,iter = 10000){\n  mar = 1:iter\n  \n  for (i in 1:iter) {\n    mar[i] = sum(dpois(x = y,lambda = rnorm(n = 1,mean = 8,sd = 1),log = TRUE))\n  }\n  return(mean( exp(mar) ))\n}\n```\n:::\n\n\nLas estimaciones de Monte-Carlo, con $m = 50,000$ iteraciones para cada modelo son:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 = Marginal1(y = InsectSprays$count,iter = 50000)\nm2 = Marginal2(y = InsectSprays$count,iter = 50000)\nm3 = Marginal1(y = InsectSprays$count,iter = 50000)\n```\n:::\n\n\nLos factores de Bayes para comparar los 3 modelos son:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFB = log(c(m1/m2,m1/m3,m2/m3))\nnames(FB) =c(\"log FB12\",\"log FB13\",\"log FB23\") \nFB\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   log FB12    log FB13    log FB23 \n-148.886381   -2.369287  146.517094 \n```\n:::\n:::\n\n\nLas estimaciones obtenidas muestran una evidencia rotunda a preferir el modelo $M_2$ sobre el modelo $M_1$ y una evidencia fuerte de preferir el modelo $M_1$ sobre el modelo $M_3$. Finalmente, hay evidencia rotunda a predecir el modelo $M_2$ sobre el modelo $M_3$.\n\nPor lo tanto, el modelo selecionado es: $M_2:$ Binomial negativa, con prior dispersa.\n\nEl mayor problema de los factores de Bayes son:\n\n + Los modelos son inestables\n \n + El modelo es muy sensible a modelos priors no informativas o muy dispersas.\n\n#### log-Verosimilitud\n\nUn estimador muy importante para la selección de modelos es la matriz de log-verosimilitudes, esta se estima por métodos de Monte-Carlo usando una muestra de la posterior $\\theta_1,\\theta_2,\\ldots,\\theta_S$, de la siguiente forma\n\n$$\\log f(y|\\theta) = [\\log f(y_i|\\theta_j)] \\in \\mathbb R^{S \\times n}$$\nLas siguientes lineas de código generan la matriz de verosimilitudes\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nloglik1 = function(y,iter = 10000){\n  loglik  = matrix(nrow = iter, ncol = length(y))\n  \n  for (i in 1:iter)  \n    loglik[i, ] = dpois(y,lambda = rgamma(1,687,75),log = TRUE)\n  \n  return(loglik)\n}\n\nloglik2 = function(y,iter = 10000){\n  loglik  = matrix(nrow = iter, ncol = length(y))\n  \n  for (i in 1:iter)  \n    loglik[i, ] = dnbinom(y,size = 30,prob = rbeta(1,2160,685),log = TRUE)\n  \n  return(loglik)\n}\n\nloglik3 = function(y,lbd){\n  loglik  = matrix(nrow = length(lbd), ncol = length(y))\n  \n  for (i in 1:length(lbd))  \n    loglik[i, ] = dpois(y,lambda = lbd[i],log = TRUE)\n  \n  return(loglik)\n}\n```\n:::\n\n\nA partir de las matrices de log-verosimilitudes se puede estimar una muestra a posteriori de la log-verosimilitud del modelo a partir de la siguiente ecuación\n\n$$\\log f(y| \\theta) = -\\sum_{i=1}^n \\log f(y_i | \\theta).$$\nEstos valores pueden utilizarse para comparación preliminar de modelos, pero como una medida absoluta, la siguiente figura muestra las posteriors de las log verosimilitudes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nll1 = loglik1(y = InsectSprays$count,iter = 8000)\nll2 = loglik2(y = InsectSprays$count,iter = 8000)\nll3 = loglik3(y = InsectSprays$count,lbd = df1$lambda)\n\nlogVero = data.frame(\n      loglik = c(apply(-ll1,1,sum),apply(-ll2,1,sum),apply(-ll3,1,sum)),\n      models = c(rep(\"M1\",8000),rep(\"M2\",8000),rep(\"M3\",8000))\n    )\n\nggplot(aes(x = loglik,fill = models),data = logVero)+\n  geom_density(alpha = 0.4)+\n  labs(title = \"Comparación de Modelos\",\n       subtitle = \"Log-verosimilitudes\",\n       x = \"Simulaciones\",y = \"densidades\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nLas log-verosimilitudes indican que el modelo $M_22$ con verosimilitud Binomial Negativa estima mucho mejor que los dos modelos con verosimilitud de Poisson.\n\n#### Expected log-Predictive density (elpd)\n\nLa elpd es una medida de divergencia entre el modelo ajustado y la distribución real de los datos que se calcula mediante la siguiente ecuación\n\n$$elpd(M_k|y) = - \\int\\log f(y^*|y) f_t(y)dy$$\nEsta propuesta esta implementada en el paquete [loo](http://mc-stan.org/loo/reference/loo-package.html), y se puede obtener a partir de la matriz log-verosimilitudes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(loo)\n\nloo1 = loo(ll1)\nloo2 = loo(ll2)\nloo3 = loo(ll3)\n\ncompare(loo1,loo2,loo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     elpd_diff se_diff elpd_loo p_loo  looic \nloo2    0.0       0.0  -304.0      4.0  608.1\nloo3  -36.6       5.9  -340.6      4.8  681.3\nloo1  -37.3       6.5  -341.4      5.5  682.8\n```\n:::\n:::\n\n\nEn este criterio el modelo $M_2$ representa el mejor modelo de los datos.\n\n#### Criterios de información de Watanabe\n\nEl criterio de información de Watanabe es asintomático al valor obtenido por la $elpd$, por lo tanto, puede ser aproximado con validación cruzada.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwaic1 = waic(ll1)\nwaic2 = waic(ll2)\nwaic3 = waic(ll3)\n\ncompare(waic1,waic2,waic3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      elpd_diff se_diff elpd_waic p_waic waic  \nwaic2    0.0       0.0  -304.0       4.0  608.1\nwaic3  -36.6       5.9  -340.6       4.7  681.2\nwaic1  -37.3       6.5  -341.4       5.5  682.7\n```\n:::\n:::\n\n\nFinalmente, elegimos al modelo $M_2$ como el mejor modelo que explica el número de insectos al aplicar un pesticida.\n\n## Referencias\n\n\n---\nnocite: |\n @Casella @degroot2012 @Miggon2014 @gelman2013 @BMLR2021 \n---\n\n\n::: {#refs}\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../site_libs/tabwid-1.1.0/tabwid.css\" rel=\"stylesheet\" />\n<link href=\"../../../site_libs/tabwid-1.1.0/scrool.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}