[
  {
    "objectID": "posts/Gaussian-LM/index.html",
    "href": "posts/Gaussian-LM/index.html",
    "title": "GLMs Gaussianos: Capacidad de Motores de carros",
    "section": "",
    "text": "Este post presenta un análisis la base mtcars usando un modelo lineal múltiple con verosimilitud Gaussiana.\nLa base de datos mtcars contiene el registro de motores de carros mas populares en USA, 1974. los datos contienen 32 registros, con 10 atributos del motor.\nSe desea predecir la capacidad de consumo de los motores, para eso se evaluaron las siguiente variables."
  },
  {
    "objectID": "posts/Gaussian-LM/index.html#verosimilitud",
    "href": "posts/Gaussian-LM/index.html#verosimilitud",
    "title": "GLMs Gaussianos: Capacidad de Motores de carros",
    "section": "Verosimilitud",
    "text": "Verosimilitud\nPara medir la relación de consumo de los motores utilizaremos un GLM normal tal que:\nmpg_i \\sim N(\\mu_i,\\sigma^2), \\quad  g(\\mu_i) = \\mu_i, \\text{ y } \\mu_i = \\beta X_i.\nEl siguiente código limpia la base de datos para obtener las variables de interés\n\n\nCode\ndf = mtcars[,c(1,4,6,8,10,11)]\nstr(df)\n\n\n'data.frame':   32 obs. of  6 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\nTodas las variables son numéricas, pero algunas son totalmente enteras, dificultando el proceso de análisis, se procede a revisar las correlaciones para revisar las interacciones lineales entre variables.\n\n\nCode\nggpairs(df)\n\n\n\n\n\nFigure 1: Gráfico de pares. La diagonal principal muestra histogramas densidades de cada una de las variables. La parte superior muestra el coeficiente de correlación entre dos variables, fila y columna. La parte inferior muestra un gráfico de dispersión entre dos variables.\n\n\n\n\nFigure 1 muestra colinealidad entre las variables mpg, hp y wt. Por lo tanto, múltiples modelos deben ser considerados. Realizemos un modelo inicial, el considerado el modelo completo que posee todas las variables\n\n\n\n\n\n\nColinealidad\n\n\n\nDos covariables X_1 y X_2 se dicen ser colineales si las variables son linealmente dependientes.\nRecordar que si dos columnas de una matriz son linealmente dependiente, entonces el determinante es cero."
  },
  {
    "objectID": "posts/Gaussian-LM/index.html#ajuste-del-modelo",
    "href": "posts/Gaussian-LM/index.html#ajuste-del-modelo",
    "title": "GLMs Gaussianos: Capacidad de Motores de carros",
    "section": "Ajuste del modelo",
    "text": "Ajuste del modelo\nAjustamos el modelo completo que consiste en usar todas las variables, y revisamos el ajuste e inferencia de los parámetros.\n\n\nCode\nm1 = lm(mpg~.,data = df)\nsummary(m1)\n\n\n\nCall:\nlm(formula = mpg ~ ., data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2884 -1.4370 -0.3155  1.1697  5.8246 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 27.20311    5.74212   4.737 6.72e-05 ***\nhp          -0.02339    0.01353  -1.728   0.0958 .  \nwt          -2.74663    0.92005  -2.985   0.0061 ** \nvs           0.94692    1.36929   0.692   0.4954    \ngear         1.78520    1.12762   1.583   0.1255    \ncarb        -0.65498    0.57767  -1.134   0.2672    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.569 on 26 degrees of freedom\nMultiple R-squared:  0.8477,    Adjusted R-squared:  0.8184 \nF-statistic: 28.94 on 5 and 26 DF,  p-value: 7.653e-10\n\n\nDebido a la alta colinealidad entre las variables, pocos parámetros estimados son significativos. Procedemos a eliminar algunas variables del modelo. Eliminamos la variable wt al ser colineal con múltiples variables. Por lo tanto, el modelo inicial M_1 es:\n\n\nCode\nm1  =  lm(mpg~vs+hp+gear+carb,data = df)\nsummary(m1)\n\n\n\nCall:\nlm(formula = mpg ~ vs + hp + gear + carb, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.8047 -2.3487 -0.0967  1.9188  6.7859 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 13.03756    3.67694   3.546  0.00145 ** \nvs           0.84671    1.55657   0.544  0.59093    \nhp          -0.03449    0.01480  -2.331  0.02747 *  \ngear         4.20129    0.89285   4.705 6.72e-05 ***\ncarb        -1.33338    0.60391  -2.208  0.03593 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.921 on 27 degrees of freedom\nMultiple R-squared:  0.7955,    Adjusted R-squared:  0.7652 \nF-statistic: 26.25 on 4 and 27 DF,  p-value: 5.825e-09"
  },
  {
    "objectID": "posts/Gaussian-LM/index.html#incertidumbre-de-los-estimadores.",
    "href": "posts/Gaussian-LM/index.html#incertidumbre-de-los-estimadores.",
    "title": "GLMs Gaussianos: Capacidad de Motores de carros",
    "section": "Incertidumbre de los estimadores.",
    "text": "Incertidumbre de los estimadores.\nPese que la función lm de R realiza un análisis de incertidumbre al presentar una Prueba-t de significacia para cada parámetro \\beta_i, no presenta los intervalos de confianza. Estos serán estimados con Bootstrap. La siguiente función obtiene una muestra Bootstrap de los parámetros desconocidos \\beta.\n\n\nCode\nlm_boots = function(y,x,B = 1000){\n  n = length(y)\n  est = NULL\n  for (i in 1:B) {\n    si = sample(x = 1:n,size = n,replace = TRUE)\n    mli = lm(y[si]~x[si,] )\n    ci = as.array(mli$coefficients)\n    est = rbind(est,ci)\n  }\n  # Estética\n  cn = colnames(x)\n  colnames(est) = c(\"intercepto\",cn)\n  \n  return(est)\n}\n\n\nObtenemos una muestra Bootstrap para los estimadores \\hat \\beta de tamaño B=5,000 repeticiones\n\n\nCode\nbtp = lm_boots(y = df$mpg,x = as.matrix(df[,-1]),B = 5000)\n\nbayesplot_theme_set(theme_grey())\nmcmc_dens(btp)+labs(title=\"Distribución muestral de los estimadores\",\n                    subtitle =\"Bootstrap B = 5,000 iteraciones\")\n\n\n\n\n\nFigure 2: Gráfico de densidades. Cada densidad representa la distribución muestral aproximada para cada uno de los estimadores usando un Bootstrap de B=5,000 iteraciones.\n\n\n\n\nLos intervalos de confianza al 95% son:\n\n\nCode\nx = apply(btp,MARGIN = 2, FUN = quantile, probs = c(0.025,0.5,0.975)) \n\n# Estética\nx = data.frame( t(x) )\nx$pars = c(\"intercepto\",\"hp\",\"wt\",\"vs\",\"gear\",\"carb\")\ncolnames(x) = c(\"q2.5%\",\"Median\",\"q97.5%\",\"parámetros\")\n\nft = flextable(x[c(4,1,2,3)])\nautofit(ft)\n\n\n\n\nTable 1:  Intervalos de confianza al 95%, obtenidos a partir de una muestra bootstrap de B = 5,000 iteraciones parámetrosq2.5%Medianq97.5%intercepto12.1214379226.9726363837.698552239hp-0.04762098-0.023802590.002979947wt-4.70923222-2.64359169-0.954013196vs-1.994957640.755290463.099198651gear0.222539631.858801095.271241021carb-2.28750766-0.741948680.310962744\n\n\n\nLos intervalos de confianza revelan mayor información a lo obtenido por la prueba-t, parámetros como hp, y carb que son significativos en la prueba, no lo son mediante los intervalos. Esto indica la posibilidad de un modelo mucho mas reducido."
  },
  {
    "objectID": "posts/Gaussian-LM/index.html#análisis-de-los-residuos",
    "href": "posts/Gaussian-LM/index.html#análisis-de-los-residuos",
    "title": "GLMs Gaussianos: Capacidad de Motores de carros",
    "section": "Análisis de los residuos",
    "text": "Análisis de los residuos\nUna vez evaluadas las estimaciones del modelo, es necesario revisar los residuos del mismo para corroborar supuestos, la siguiente linea de código presenta un resumen descriptivo de los residuos del modelo inicial M_1, en su mayoría parecen estar centrados en cero.\n\n\nCode\nsummary(m1$residuals)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-3.80470 -2.34875 -0.09674  0.00000  1.91880  6.78592 \n\n\nFigure 3 presenta una visualización típica para el diagnostico de los residuos, ninguna figura debe presentar un comportamiento polinómico a excepción del gráfico de quantiles (derecha superior), que debe seguir el comportamiento de una función lineal creciente.\n\n\nCode\nautoplot(m1)\n\n\n\n\n\nFigure 3: Gráfico diagnóstico de los residuos, estos cuatro gráficos evaluan el ajuste y supuestos del modelo, si algún comportamiento polinómico es persistente, entonces los supuestos del modelo no se satisfacen."
  },
  {
    "objectID": "posts/Gaussian-LM/index.html#selección-de-modelos",
    "href": "posts/Gaussian-LM/index.html#selección-de-modelos",
    "title": "GLMs Gaussianos: Capacidad de Motores de carros",
    "section": "Selección de modelos",
    "text": "Selección de modelos\nAdicional al modelo M_1, ajustamos dos modelos mas:\nM_2: \\quad mpg \\sim N(hp+gear+carb,\\sigma^2), M_3: \\quad mpg \\sim N(wt+gear+carb,\\sigma^2).\n\n\nCode\nm2 = lm(mpg~hp+gear+carb,data = df)\nm3 = lm(mpg~wt+gear+carb,data = df)\n\n\nEl siguiente código calcula el RMSE de un modelo linea en el conjunto de entrenamiento.\n\n\nCode\nrmse = function(m){\n  mse = sum(m$residuals^2)/length(m$residuals)\n  return(sqrt(mse))\n}\n\n\n\n\nCode\nx = matrix(0,nrow = 4,ncol = 3)\nx[1,] = c(logLik(m1),logLik(m2),logLik(m3))\nx[2,] = c(AIC(m1),AIC(m2),AIC(m3))\nx[3,] = c(BIC(m1),BIC(m2),BIC(m3))\nx[4,] = c(rmse(m1),rmse(m2),rmse(m3))\n\n# Estética\nx = data.frame(x)\nx$pars =  c(\"logLik\",\"AIC\",\"BIC\",\"RMSE\")\ncolnames(x)  = c(\"Modelo 1\",\"Modelo 2\",\"Modelo 3\",\"Criterio\")\n\nft = flextable(x[c(4,1,2,3)])\nautofit(ft)\n\n\n\n\nTable 2:  Criterios de información de los modelos. Se selecciona el modelo con menores criterios. CriterioModelo 1Modelo 2Modelo 3logLik-76.986353-77.160742-75.196419AIC165.972706164.321484160.392838BIC174.767122171.650163167.721517RMSE2.6828642.6975252.536917\n\n\n\nTable 2 muestra la tabla de criterios de información para el conjunto de datos mtcars para sorpresa del lector el mejor modelo es el alternativo M_3 que usa la variable colineal wt en vez de hp."
  },
  {
    "objectID": "posts/Gaussian-LM/index.html#validación-cruzada",
    "href": "posts/Gaussian-LM/index.html#validación-cruzada",
    "title": "GLMs Gaussianos: Capacidad de Motores de carros",
    "section": "Validación cruzada",
    "text": "Validación cruzada\nEl siguiente código presenta una función para realizar k-fold-CV para cualquier valor de k. En caso de querer añadir otros modelos o criterios, la función deberá ser modificada.\n\n\nCode\nkfold = function(df,k){\n  # Generar la particion\n  kfld = createFolds(df[,1],k = k)\n  mat = NULL\n  \n  for (i in 1:k) {\n    # separar los datos en conjuntos de prueba y entrenamiento\n    dfE= df[-kfld[[i]],]\n    dfP = df[kfld[[i]],]\n    # Ajustar los modelos\n    m1 = lm(mpg~vs+hp+gear+carb,data = dfE)\n    m2 = lm(mpg~hp+gear+carb,data = dfE)\n    m3 = lm(mpg~wt+gear+carb,data = dfE)\n    \n    p1 = predict(m1,dfP)\n    p2 = predict(m2,dfP)\n    p3 = predict(m3,dfP)\n    # Calcular AIC y RMSE\n    aic = c(\n            AIC(m1),\n            AIC(m2),\n            AIC(m3)\n            )\n    rmse = c(\n             RMSE(pred =  p1,obs = dfP[,1]),\n             RMSE(pred =  p2,obs = dfP[,1]),\n             RMSE(pred =  p3,obs = dfP[,1])\n             )\n    mae = c(\n            MAE(pred =  p1,obs = dfP[,1]),\n            MAE(pred =  p2,obs = dfP[,1]),\n            MAE(pred =  p3,obs = dfP[,1])\n            )\n    mape = c(\n              mean(abs((p1-dfP[,1])/dfP[,1])),\n              mean(abs((p2-dfP[,1])/dfP[,1])),\n              mean(abs((p3-dfP[,1])/dfP[,1]))\n              )\n    # Unir los datos\n    mat = rbind(mat,c(aic,rmse,mae,mape)) \n  }\n  colnames(mat) = c(\"AIC1\",\"AIC2\",\"AIC3\",\"RMSE1\",\"RMSE2\",\"RMSE3\",\"MAE1\",\"MAE2\",\n                    \"MAE3\",\"MAPE1\",\"MAPE2\",\"MAPE3\")\n  row.names(mat) = NULL\n  return(mat)\n}\n\n\nTable 3 presenta los resultados obtenidos al realizar 5-fold-cv, bajo todos los criterios presentados, el modelo M_3 presenta las mejores predicciones. Por lo tanto, M_3 es el modelo con Mayor aprendizaje.\n\n\nCode\nrst = kfold(df = df,k = 5)\nx = t(apply(rst,MARGIN = 2,FUN = \"quantile\",probs = c(0.025,0.5,0.975)))\n\n# Estética\nx = data.frame(x)\nx$pars =  c(\"AIC1\",\"AIC2\",\"AIC3\",\"RMSE1\",\"RMSE2\",\"RMSE3\",\"MAE1\",\"MAE2\",\n                    \"MAE3\",\"MAPE1\",\"MAPE2\",\"MAPE3\")\ncolnames(x) = c(\"q2.5%\",\"Median\",\"q97.5%\",\"Criterio\")\n\nft = flextable(x[c(4,1,2,3)])\nautofit(ft)\n\n\n\n\nTable 3:  Criterios de información de los modelos. Mediante Validación cruzada. La tabla presenta los criterios AIC, RMSE, MAE y MAPE bajo un 10-fold cv. Criterioq2.5%Medianq97.5%AIC1129.89079860133.8847343137.8463322AIC2128.24651116131.9044568135.9207489AIC3125.28914666129.7135001131.3318842RMSE12.331849362.69174614.7960982RMSE22.239319132.60336044.8245757RMSE31.865671543.23902624.5435248MAE12.063445742.40001354.0644025MAE21.943991452.14707824.1105977MAE31.436596152.07664053.6137624MAPE10.109575680.13294630.1627171MAPE20.101673950.13522770.1646107MAPE30.068356620.12849530.1629922"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Bayesian Modeling",
    "section": "",
    "text": "Gaussian\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\nAsael Alonzo Matamoros\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nRegression\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2022\n\n\nAsael Alonzo Matamoros.\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\nintroduction\n\n\nBaseline\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2022\n\n\nAsael Alonzo Matamoros\n\n\n\n\n\n\nNo matching items"
  }
]