---
title: "GLMs Gaussianos"
subtitle: "Capacidad de Motores de carros"
author: "Asael Alonzo Matamoros"
date: "2022-11-15"
categories: [Gaussian,code,analysis]
image: "image.jpg"
bibliography: ref.bib
format: 
  html:
    toc: true
    code-copy: true
    smooth-scroll: true
    anchor-sections: true
---

Este post presenta un análisis la base `mtcars` usando un modelo lineal múltiple con verosimilitud Gaussiana. 

La base de datos `mtcars` contiene el registro de motores de carros mas populares en USA, 1974. los datos contienen 32 registros, con 10 atributos del motor.

```{r}
#| message: false
library(caret)
library(GGally)
library(ggplot2)
library(flextable)
library(bayesplot)
library(ggfortify)
```

Se desea predecir la capacidad de consumo de los motores, para eso se evaluaron las siguiente variables.

 + `mpg`: Millas por Galón. (**Dependiente**)

 + `hp`: Caballos de fuerza.

 + `carb`: número de carburadores.
 
 + `wt`: peso del motor.
 
 + `gears`: Número de cambios.
 
 + `vs`: tipo de motor, `recto:1` o `tipo V:0`.

## Verosimilitud
 
Para medir la relación de consumo de los motores utilizaremos un GLM normal tal que:

$$mpg_i \sim N(\mu_i,\sigma^2), \quad  g(\mu_i) = \mu_i, \text{ y } \mu_i = \beta X_i.$$

El siguiente código limpia la base de datos para obtener las variables de interés

```{r}
df = mtcars[,c(1,4,6,8,10,11)]
str(df)
```
 
Todas las variables son numéricas, pero algunas son totalmente enteras, dificultando el proceso de análisis, se procede a revisar las correlaciones para revisar las interacciones lineales entre variables.

```{r}
#| label: fig-pairs
#| fig-cap: "Gráfico de pares. La diagonal principal muestra histogramas densidades de cada una de las variables. La parte superior muestra el coeficiente de correlación entre dos variables, fila y columna. La parte inferior muestra un gráfico de dispersión entre dos variables."
ggpairs(df)
``` 
  
@fig-pairs muestra colinealidad entre las variables `mpg, hp` y `wt`. Por lo tanto, múltiples modelos deben ser considerados. Realizemos un modelo inicial, el considerado el modelo completo que posee todas las variables

::: {.callout-note}

### Colinealidad

Dos covariables $X_1$ y $X_2$ se dicen ser **colineales** si las variables son **linealmente dependientes**. 

Recordar que si dos columnas de una matriz son linealmente dependiente, entonces el determinante es cero.

:::

## Ajuste del modelo

Ajustamos el modelo completo que consiste en usar todas las variables, y revisamos el ajuste e inferencia de los parámetros.

```{r}
m1 = lm(mpg~.,data = df)
summary(m1)
```

Debido a la alta colinealidad entre las variables, pocos parámetros estimados son significativos.  Procedemos a eliminar algunas variables del modelo. Eliminamos la variable `wt` al ser colineal con múltiples variables. Por lo tanto, el modelo inicial $M_1$ es:

```{r}
m1  =  lm(mpg~vs+hp+gear+carb,data = df)
summary(m1)
```

## Incertidumbre de los estimadores.

Pese que la función `lm` de `R` realiza un análisis de incertidumbre al presentar una *Prueba-t* de significacia para cada parámetro $\beta_i$, no presenta los intervalos de confianza. Estos serán estimados con **Bootstrap**. La siguiente función obtiene una muestra Bootstrap de los parámetros desconocidos $\beta$.

```{r}
lm_boots = function(y,x,B = 1000){
  n = length(y)
  est = NULL
  for (i in 1:B) {
    si = sample(x = 1:n,size = n,replace = TRUE)
    mli = lm(y[si]~x[si,] )
    ci = as.array(mli$coefficients)
    est = rbind(est,ci)
  }
  # Estética
  cn = colnames(x)
  colnames(est) = c("intercepto",cn)
  
  return(est)
}
```

Obtenemos una muestra Bootstrap para los estimadores $\hat \beta$ de tamaño $B=5,000$ repeticiones

```{r}
#| label: fig-btp
#| fig-cap: "Gráfico de densidades. Cada densidad representa la distribución muestral aproximada para cada uno de los estimadores usando un Bootstrap de B=5,000 iteraciones."
btp = lm_boots(y = df$mpg,x = as.matrix(df[,-1]),B = 5000)

bayesplot_theme_set(theme_grey())
mcmc_dens(btp)+labs(title="Distribución muestral de los estimadores",
                    subtitle ="Bootstrap B = 5,000 iteraciones")
```

Los intervalos de confianza al 95% son:

```{r}
#| label: tbl-btp
#| tbl-cap: "Intervalos de confianza al 95%, obtenidos a partir de una muestra bootstrap de B = 5,000 iteraciones"
x = apply(btp,MARGIN = 2, FUN = quantile, probs = c(0.025,0.5,0.975)) 

# Estética
x = data.frame( t(x) )
x$pars = c("intercepto","hp","wt","vs","gear","carb")
colnames(x) = c("q2.5%","Median","q97.5%","parámetros")

ft = flextable(x[c(4,1,2,3)])
autofit(ft)
```

Los intervalos de confianza revelan mayor información a lo obtenido por la prueba-t, parámetros como `hp`, y `carb` que son significativos en la prueba, no lo son mediante los intervalos. Esto indica la posibilidad de un modelo mucho mas reducido.

## Análisis de los residuos

Una vez evaluadas las estimaciones del modelo, es necesario revisar los residuos del mismo para corroborar supuestos, la siguiente linea de código presenta un resumen descriptivo de los residuos del modelo inicial $M_1$, en su mayoría  parecen estar centrados en cero.

```{r}
summary(m1$residuals)
```

@fig-res1 presenta una visualización típica para el diagnostico de los residuos, ninguna figura debe presentar un comportamiento polinómico a excepción del gráfico de quantiles (*derecha superior*), que debe seguir el comportamiento de una función lineal creciente.

```{r}
#| label: fig-res1
#| fig-cap: "Gráfico diagnóstico de los residuos, estos cuatro gráficos evaluan el ajuste y supuestos del modelo, si  algún comportamiento polinómico es persistente, entonces los supuestos del modelo no se satisfacen."
autoplot(m1)
```

## Selección de modelos

Adicional al modelo $M_1$, ajustamos dos modelos mas: 

$$M_2: \quad mpg \sim N(hp+gear+carb,\sigma^2),$$
$$M_3: \quad mpg \sim N(wt+gear+carb,\sigma^2).$$
```{r}
m2 = lm(mpg~hp+gear+carb,data = df)
m3 = lm(mpg~wt+gear+carb,data = df)
```

El siguiente código calcula el $RMSE$ de un modelo linea en el conjunto de entrenamiento.

```{r}
#| code-fold: true
rmse = function(m){
  mse = sum(m$residuals^2)/length(m$residuals)
  return(sqrt(mse))
}
```


```{r}
#| label: tbl-criteria
#| tbl-cap: "Criterios de información de los modelos. Se selecciona el modelo con menores criterios."
x = matrix(0,nrow = 4,ncol = 3)
x[1,] = c(logLik(m1),logLik(m2),logLik(m3))
x[2,] = c(AIC(m1),AIC(m2),AIC(m3))
x[3,] = c(BIC(m1),BIC(m2),BIC(m3))
x[4,] = c(rmse(m1),rmse(m2),rmse(m3))

# Estética
x = data.frame(x)
x$pars =  c("logLik","AIC","BIC","RMSE")
colnames(x)  = c("Modelo 1","Modelo 2","Modelo 3","Criterio")

ft = flextable(x[c(4,1,2,3)])
autofit(ft)
```

@tbl-criteria muestra la tabla de criterios de información para el conjunto de datos `mtcars` para sorpresa del lector el mejor modelo es el alternativo $M_3$ que usa la variable colineal `wt` en vez de `hp`.

## Validación cruzada

El siguiente código presenta una función para realizar **k-fold-CV** para cualquier valor de $k$. En caso de querer añadir otros modelos o criterios, la función deberá ser modificada.

```{r}
#| code-fold: true
kfold = function(df,k){
  # Generar la particion
  kfld = createFolds(df[,1],k = k)
  mat = NULL
  
  for (i in 1:k) {
    # separar los datos en conjuntos de prueba y entrenamiento
    dfE= df[-kfld[[i]],]
    dfP = df[kfld[[i]],]
    # Ajustar los modelos
    m1 = lm(mpg~vs+hp+gear+carb,data = dfE)
    m2 = lm(mpg~hp+gear+carb,data = dfE)
    m3 = lm(mpg~wt+gear+carb,data = dfE)
    
    p1 = predict(m1,dfP)
    p2 = predict(m2,dfP)
    p3 = predict(m3,dfP)
    # Calcular AIC y RMSE
    aic = c(
            AIC(m1),
            AIC(m2),
            AIC(m3)
            )
    rmse = c(
             RMSE(pred =  p1,obs = dfP[,1]),
             RMSE(pred =  p2,obs = dfP[,1]),
             RMSE(pred =  p3,obs = dfP[,1])
             )
    mae = c(
            MAE(pred =  p1,obs = dfP[,1]),
            MAE(pred =  p2,obs = dfP[,1]),
            MAE(pred =  p3,obs = dfP[,1])
            )
    mape = c(
              mean(abs((p1-dfP[,1])/dfP[,1])),
              mean(abs((p2-dfP[,1])/dfP[,1])),
              mean(abs((p3-dfP[,1])/dfP[,1]))
              )
    # Unir los datos
    mat = rbind(mat,c(aic,rmse,mae,mape)) 
  }
  colnames(mat) = c("AIC1","AIC2","AIC3","RMSE1","RMSE2","RMSE3","MAE1","MAE2",
                    "MAE3","MAPE1","MAPE2","MAPE3")
  row.names(mat) = NULL
  return(mat)
}
```

@tbl-cv presenta los resultados obtenidos al realizar 5-fold-cv, bajo todos los criterios presentados, el modelo $M_3$ presenta las mejores predicciones. Por lo tanto, $M_3$ es el modelo con Mayor aprendizaje.

```{r}
#| label: tbl-cv
#| tbl-cap: "Criterios de información de los modelos. Mediante Validación cruzada. La tabla presenta los criterios AIC, RMSE, MAE y MAPE bajo un 10-fold cv."

rst = kfold(df = df,k = 5)
x = t(apply(rst,MARGIN = 2,FUN = "quantile",probs = c(0.025,0.5,0.975)))

# Estética
x = data.frame(x)
x$pars =  c("AIC1","AIC2","AIC3","RMSE1","RMSE2","RMSE3","MAE1","MAE2",
                    "MAE3","MAPE1","MAPE2","MAPE3")
colnames(x) = c("q2.5%","Median","q97.5%","Criterio")

ft = flextable(x[c(4,1,2,3)])
autofit(ft)
```


## Referencias

---
nocite: |
 @Casella @degroot2012 @Miggon2014 @gelman2013 @BMLR2021 
---

::: {#refs}
:::
